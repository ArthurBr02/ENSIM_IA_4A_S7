{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV5LCtrtdgG1"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-12T09:41:50.858243Z",
          "start_time": "2025-11-12T09:41:39.980443Z"
        },
        "id": "twkLFThedgG5"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n"
      ],
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-12T09:42:18.480183Z",
          "start_time": "2025-11-12T09:41:51.855704Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHM808lDdgG8",
        "outputId": "9f2e4d1d-5041-4110-c52f-c2a79ee654e0"
      },
      "source": [
        "# Define relevant variables for the ML task\n",
        "batch_size = 64\n",
        "\n",
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 13.3MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 210kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.92MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 14.6MB/s]\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dN11GR2dgG_"
      },
      "source": [
        "# Define your CNN network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tey-i-f8dgHA"
      },
      "source": [
        "we start by creating a class that inherits the nn.Module class, and then we define the layers and their sequence of execution inside \\_\\_init\\_\\_ and forward respectively.\n",
        "\n",
        "Some things to notice here:\n",
        "\n",
        "- nn.Conv2d is used to define the convolutional layers. We define the channels they receive and how much should they return along with the kernel size. We start from 1 channels, as we are using Grayscale images\n",
        "- nn.MaxPool2d is a max-pooling layer that just requires the kernel size and the stride\n",
        "- nn.Linear is the fully connected layer, and nn.ReLU is the activation function used\n",
        "\n",
        "In the forward method, we define the sequence, and, before the fully connected layers, we reshape the output to match the input to a fully connected layer\n",
        "\n",
        "Source: https://blog.paperspace.com/writing-cnns-from-scratch-in-pytorch/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-12T09:44:35.074826Z",
          "start_time": "2025-11-12T09:44:35.050778Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "ApTANoAydgHB",
        "outputId": "7984a737-5761-4264-a43e-50e492c17d81"
      },
      "source": [
        "# @title\n",
        "# Creating a CNN class\n",
        "class ConvNeuralNet(torch.nn.Module):\n",
        "    #  Determine what layers and their order in CNN object\n",
        "    def __init__(self, num_classes):\n",
        "        super(ConvNeuralNet, self).__init__()\n",
        "        self.conv_layer1 = torch.nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n",
        "        self.max_pool1 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv_layer2 = torch.nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3)\n",
        "        self.max_pool2 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.relu1 = torch.nn.ReLU()\n",
        "        self.fc1 = torch.nn.Linear(400, num_classes)\n",
        "\n",
        "    # Progresses data across layers\n",
        "    def forward(self, x):\n",
        "        out = self.conv_layer1(x)\n",
        "        out = self.max_pool1(out)\n",
        "\n",
        "        out = self.conv_layer2(out)\n",
        "        out = self.max_pool2(out)\n",
        "\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc1(out)\n",
        "        return out\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\\n\")\n",
        "\n",
        "model = ConvNeuralNet(10).to(device)\n",
        "print(model)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Number of Parameters:{total_params}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "\n",
            "ConvNeuralNet(\n",
            "  (conv_layer1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv_layer2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (relu1): ReLU()\n",
            "  (fc1): Linear(in_features=200, out_features=10, bias=True)\n",
            ")\n",
            "Number of Parameters:2346\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Creating a CNN class\n",
        "class ConvNeuralNet(torch.nn.Module):\n",
        "    #  Determine what layers and their order in CNN object\n",
        "    def __init__(self, num_classes):\n",
        "        super(ConvNeuralNet, self).__init__()\n",
        "        self.conv_layer1 = torch.nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3)\n",
        "        self.max_pool1 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv_layer2 = torch.nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3)\n",
        "        self.max_pool2 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.relu1 = torch.nn.ReLU()\n",
        "        self.fc1 = torch.nn.Linear(200, num_classes)\n",
        "\n",
        "    # Progresses data across layers\n",
        "    def forward(self, x):\n",
        "        out = self.conv_layer1(x)\n",
        "        out = self.max_pool1(out)\n",
        "\n",
        "        out = self.conv_layer2(out)\n",
        "        out = self.max_pool2(out)\n",
        "\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc1(out)\n",
        "        return out\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\\n\")\n",
        "\n",
        "model = ConvNeuralNet(10).to(device)\n",
        "print(model)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Number of Parameters:{total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "iF5z0IgHfkm1",
        "outputId": "bff122d7-b62f-41b9-da9b-9e99c40c86fe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "\n",
            "ConvNeuralNet(\n",
            "  (conv_layer1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv_layer2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (relu1): ReLU()\n",
            "  (fc1): Linear(in_features=1152, out_features=10, bias=True)\n",
            ")\n",
            "Number of Parameters:11866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Creating a CNN class\n",
        "class ConvNeuralNet(torch.nn.Module):\n",
        "    #  Determine what layers and their order in CNN object\n",
        "    def __init__(self, num_classes):\n",
        "        super(ConvNeuralNet, self).__init__()\n",
        "        self.conv_layer1 = torch.nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3)\n",
        "\n",
        "        self.conv_layer2 = torch.nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3)\n",
        "        self.max_pool2 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.relu1 = torch.nn.ReLU()\n",
        "        self.fc1 = torch.nn.Linear(1152, num_classes)\n",
        "\n",
        "    # Progresses data across layers\n",
        "    def forward(self, x):\n",
        "        out = self.conv_layer1(x)\n",
        "\n",
        "        out = self.conv_layer2(out)\n",
        "        out = self.max_pool2(out)\n",
        "\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc1(out)\n",
        "        return out\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\\n\")\n",
        "\n",
        "model = ConvNeuralNet(10).to(device)\n",
        "print(model)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Number of Parameters:{total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "0qXYQw4ifkV2",
        "outputId": "66a3546a-7b7e-4185-9626-962313f8d6db"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "\n",
            "ConvNeuralNet(\n",
            "  (conv_layer1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv_layer2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (relu1): ReLU()\n",
            "  (fc1): Linear(in_features=1152, out_features=10, bias=True)\n",
            ")\n",
            "Number of Parameters:11866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a CNN class\n",
        "class ConvNeuralNet(torch.nn.Module):\n",
        "    #  Determine what layers and their order in CNN object\n",
        "    def __init__(self, num_classes):\n",
        "        super(ConvNeuralNet, self).__init__()\n",
        "        self.conv_layer1 = torch.nn.Conv2d(in_channels=1, out_channels=8, kernel_size=2)\n",
        "        self.max_pool1 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "\n",
        "        self.conv_layer1_5 = torch.nn.Conv2d(in_channels=8, out_channels=8, kernel_size=2)\n",
        "        self.max_pool1_5 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv_layer2 = torch.nn.Conv2d(in_channels=8, out_channels=16, kernel_size=2)\n",
        "        self.max_pool2 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.relu1 = torch.nn.ReLU()\n",
        "        self.fc1 = torch.nn.Linear(64, num_classes)\n",
        "\n",
        "    # Progresses data across layers\n",
        "    def forward(self, x):\n",
        "        out = self.conv_layer1(x)\n",
        "        # print(\"Conv Layer 1:\", out.shape)\n",
        "        out = self.max_pool1(out)\n",
        "        # print(\"Max Pool 1:\", out.shape)\n",
        "\n",
        "        out = self.conv_layer1_5(out)\n",
        "        # print(\"Conv Layer 1_5:\", out.shape)\n",
        "        out = self.max_pool1_5(out)\n",
        "        # print(\"Max Pool 1_5:\", out.shape)\n",
        "\n",
        "        out = self.conv_layer2(out)\n",
        "        # print(\"Conv Layer 2:\", out.shape)\n",
        "        out = self.max_pool2(out)\n",
        "        # print(\"Max Pool 2:\", out.shape)\n",
        "\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        # print(\"Reshape:\", out.shape)\n",
        "\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc1(out)\n",
        "        return out\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\\n\")\n",
        "\n",
        "model = ConvNeuralNet(10).to(device)\n",
        "print(model)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Number of Parameters:{total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIBMh403i2oG",
        "outputId": "364ab04f-4332-42b3-e025-d54dd48da02d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "\n",
            "ConvNeuralNet(\n",
            "  (conv_layer1): Conv2d(1, 8, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv_layer1_5): Conv2d(8, 8, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (max_pool1_5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv_layer2): Conv2d(8, 16, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (relu1): ReLU()\n",
            "  (fc1): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "Number of Parameters:1482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-12T09:44:46.360352Z",
          "start_time": "2025-11-12T09:44:46.342914Z"
        },
        "cellView": "form",
        "id": "XHswSDFfdgHC"
      },
      "source": [
        "# @title\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "outputs": [],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true,
          "is_executing": true
        },
        "tags": [],
        "ExecuteTime": {
          "start_time": "2025-11-12T09:45:11.332731Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXhncfVPdgHD",
        "outputId": "02db26a8-002d-4d78-82d2-b038b92fecf4"
      },
      "source": [
        "# Define relevant variables for the ML task\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "num_epochs = 20\n",
        "\n",
        "# Set Loss function with criterion\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# Set optimizer with optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)\n",
        "\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.310645  [    0/60000]\n",
            "loss: 2.290847  [ 6400/60000]\n",
            "loss: 2.299369  [12800/60000]\n",
            "loss: 2.295385  [19200/60000]\n",
            "loss: 2.296859  [25600/60000]\n",
            "loss: 2.280128  [32000/60000]\n",
            "loss: 2.281440  [38400/60000]\n",
            "loss: 2.271632  [44800/60000]\n",
            "loss: 2.245576  [51200/60000]\n",
            "loss: 2.201687  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 31.3%, Avg loss: 2.173136 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.178939  [    0/60000]\n",
            "loss: 2.053109  [ 6400/60000]\n",
            "loss: 1.724094  [12800/60000]\n",
            "loss: 1.271051  [19200/60000]\n",
            "loss: 1.047569  [25600/60000]\n",
            "loss: 0.913065  [32000/60000]\n",
            "loss: 0.982864  [38400/60000]\n",
            "loss: 0.920723  [44800/60000]\n",
            "loss: 0.910908  [51200/60000]\n",
            "loss: 0.788044  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 66.7%, Avg loss: 0.934161 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.749577  [    0/60000]\n",
            "loss: 0.686194  [ 6400/60000]\n",
            "loss: 0.806464  [12800/60000]\n",
            "loss: 0.861688  [19200/60000]\n",
            "loss: 0.695192  [25600/60000]\n",
            "loss: 0.767218  [32000/60000]\n",
            "loss: 0.969284  [38400/60000]\n",
            "loss: 0.735805  [44800/60000]\n",
            "loss: 0.618970  [51200/60000]\n",
            "loss: 0.730560  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 71.8%, Avg loss: 0.785906 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.827984  [    0/60000]\n",
            "loss: 0.648935  [ 6400/60000]\n",
            "loss: 0.798531  [12800/60000]\n",
            "loss: 0.584702  [19200/60000]\n",
            "loss: 0.735492  [25600/60000]\n",
            "loss: 0.657660  [32000/60000]\n",
            "loss: 0.705393  [38400/60000]\n",
            "loss: 0.707596  [44800/60000]\n",
            "loss: 1.066984  [51200/60000]\n",
            "loss: 0.680393  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 72.9%, Avg loss: 0.736559 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.585200  [    0/60000]\n",
            "loss: 0.691009  [ 6400/60000]\n",
            "loss: 0.756346  [12800/60000]\n",
            "loss: 0.851274  [19200/60000]\n",
            "loss: 0.487118  [25600/60000]\n",
            "loss: 0.625117  [32000/60000]\n",
            "loss: 0.765097  [38400/60000]\n",
            "loss: 0.728385  [44800/60000]\n",
            "loss: 0.723873  [51200/60000]\n",
            "loss: 0.580894  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 74.8%, Avg loss: 0.722671 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.890659  [    0/60000]\n",
            "loss: 0.611911  [ 6400/60000]\n",
            "loss: 0.703937  [12800/60000]\n",
            "loss: 0.727719  [19200/60000]\n",
            "loss: 0.879353  [25600/60000]\n",
            "loss: 0.699646  [32000/60000]\n",
            "loss: 0.605598  [38400/60000]\n",
            "loss: 0.572191  [44800/60000]\n",
            "loss: 0.827300  [51200/60000]\n",
            "loss: 0.742041  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 75.6%, Avg loss: 0.677419 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.586055  [    0/60000]\n",
            "loss: 0.663281  [ 6400/60000]\n",
            "loss: 0.595384  [12800/60000]\n",
            "loss: 0.712526  [19200/60000]\n",
            "loss: 0.636484  [25600/60000]\n",
            "loss: 0.588551  [32000/60000]\n",
            "loss: 0.641689  [38400/60000]\n",
            "loss: 0.536937  [44800/60000]\n",
            "loss: 0.515787  [51200/60000]\n",
            "loss: 0.592645  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 76.4%, Avg loss: 0.659349 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.557776  [    0/60000]\n",
            "loss: 0.534974  [ 6400/60000]\n",
            "loss: 0.630789  [12800/60000]\n",
            "loss: 0.718931  [19200/60000]\n",
            "loss: 0.631875  [25600/60000]\n",
            "loss: 0.575260  [32000/60000]\n",
            "loss: 0.600039  [38400/60000]\n",
            "loss: 0.597925  [44800/60000]\n",
            "loss: 0.678427  [51200/60000]\n",
            "loss: 0.517692  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 76.9%, Avg loss: 0.634552 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.493607  [    0/60000]\n",
            "loss: 0.681905  [ 6400/60000]\n",
            "loss: 0.571681  [12800/60000]\n",
            "loss: 0.591707  [19200/60000]\n",
            "loss: 0.849006  [25600/60000]\n",
            "loss: 0.832274  [32000/60000]\n",
            "loss: 0.531346  [38400/60000]\n",
            "loss: 0.560153  [44800/60000]\n",
            "loss: 0.538529  [51200/60000]\n",
            "loss: 0.432145  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 77.2%, Avg loss: 0.628432 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.693185  [    0/60000]\n",
            "loss: 0.470266  [ 6400/60000]\n",
            "loss: 0.517009  [12800/60000]\n",
            "loss: 0.561727  [19200/60000]\n",
            "loss: 0.582440  [25600/60000]\n",
            "loss: 0.689111  [32000/60000]\n",
            "loss: 0.525605  [38400/60000]\n",
            "loss: 0.704032  [44800/60000]\n",
            "loss: 0.684926  [51200/60000]\n",
            "loss: 0.497257  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 77.7%, Avg loss: 0.617721 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "execution_count": 49
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_KneOM5dgHF"
      },
      "source": [
        "<div style=\"border: solid 3px #fff;\">\n",
        "    <h1 style=\"text-align: center; color:#fff; font-family:Georgia; font-size:26px;\">Exercise :</h1>\n",
        "    <h1 style=\"text-align: left; color:#fff; font-family:Courier; font-size:16px;\"> &emsp; Change the out_channels of the first conv2d layer to 4 and the out_channels of the second conv2d layer to 8. It is necessory to adapt the rest of layer to this new size. Check that if the training can be done. </h1>\n",
        "    <h1 style=\"text-align: left; color:#fff; font-family:Courier; font-size:16px;\"> &emsp; 1. By this modification, how much the number of parameters would be reduced? </h1>\n",
        "    <p style='text-align: left;'> </p>\n",
        "    <h1 style=\"text-align: left; color:#fff; font-family:Courier; font-size:16px;\"> &emsp; 2. How would this modification has impact on training and convergence? </h1>\n",
        "    <p style='text-align: left;'> </p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zAXP5aoydgHF"
      },
      "outputs": [],
      "source": [
        "# Le nombre de paramètre a diminué de plus de 3000 (il en reste environ 2300)\n",
        "# Avant la modification on était à environ 84.3% de précision, après la modification on atteint 83.1%. On a donc perdu en précision mais ce n'est pas\n",
        "# proportionnel à la diminution du nombre de paramètres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hQKfbxxdgHG"
      },
      "source": [
        "<div style=\"border: solid 3px #fff;\">\n",
        "    <h1 style=\"text-align: center; color:#fff; font-family:Georgia; font-size:26px;\">Exercise :</h1>\n",
        "    <h1 style=\"text-align: left; color:#fff; font-family:Courier; font-size:16px;\"> &emsp; Remove the first MaxPool2d layer and adapt the size of the rest of layers to be trainable. </h1>\n",
        "    <h1 style=\"text-align: left; color:#fff; font-family:Courier; font-size:16px;\"> &emsp; 1. By this modification, how the number of parameters would change? Does it mean that MAxPool layer contains trainable parameters?</h1>\n",
        "    <p style='text-align: left;'> </p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "8j54en2jdgHH"
      },
      "outputs": [],
      "source": [
        "# Le nombre de paramètres a augmenté pour atteindre 11866. MaxPool réduit le nombre de paramètres\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbhciTE1dgHH"
      },
      "source": [
        "<div style=\"border: solid 3px #fff;\">\n",
        "    <h1 style=\"text-align: center; color:#fff; font-family:Georgia; font-size:26px;\">Exercise :</h1>\n",
        "    <h1 style=\"text-align: left; color:#fff; font-family:Courier; font-size:16px;\"> &emsp; By using a print of the out.shape() in the function of forward in Network class, the size of each layer's output can be diplayed (ONLY in the training mode.) </h1>\n",
        "    <h1 style=\"text-align: left; color:#fff; font-family:Courier; font-size:16px;\"> &emsp; 1. Add another Conv2d with stride=2 and MaxPool2d with stride=2 beween the first MaxPool2d and the second Conv2d layer.</h1>\n",
        "    <h1 style=\"text-align: left; color:#fff; font-family:Courier; font-size:16px;\"> &emsp; 2. Modify the kenel size to 2 in Conv2d layers. Adapt the rest of layers size to have a trainable network.</h1>\n",
        "    <h1 style=\"text-align: left; color:#fff; font-family:Courier; font-size:16px;\"> &emsp; 3. While another Conv2d layer is added, how is the number of model's parameters changed?.</h1>\n",
        "    <p style='text-align: left;'> </p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzG_QcYjdgHI"
      },
      "outputs": [],
      "source": [
        "# your code is missing here\n",
        "#Le nombre de paramètres à diminué car on a ajouté une couche de pooling et réduit la taille du kernel des couches de convolution"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}