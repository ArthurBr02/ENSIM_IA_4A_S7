# Plan d'Impl√©mentation - TP IA

## Vue d'ensemble

Ce plan d√©taille les √©tapes d'impl√©mentation pour optimiser les mod√®les de deep learning selon les crit√®res d'√©valuation du TP.

---

## Phase 1 : Infrastructure et Configuration ‚úÖ TERMIN√âE

### 1.1 Cr√©ation d'une configuration centralis√©e des hyperparam√®tres ‚úÖ

**Fichier cr√©√© : `config_experiments.py`**

```python
EXPERIMENT_CONFIG = {
    "models": ["MLP", "LSTM", "CNN", "CNN_LSTM", "Transformer"],
    "optimizers": ["Adam", "Adagrad", "SGD"],
    "learning_rates": [0.0001, 0.001, 0.01, 0.1],
    "batch_sizes": [32, 64, 128, 256],
    "epochs": [10, 25, 50, 100],
    "architectures": {
        "MLP": {
            "hidden_layers": [[128], [256], [128, 64], [256, 128], [256, 128, 64]],
            "dropout": [0.0, 0.2, 0.3, 0.5]
        },
        "LSTM": {
            "hidden_sizes": [64, 128, 256],
            "num_layers": [1, 2, 3],
            "dropout": [0.0, 0.2, 0.3, 0.5]
        },
        "CNN": {
            "filters": [[32, 64], [64, 128], [32, 64, 128]],
            "kernel_sizes": [3, 5],
            "dropout": [0.0, 0.2, 0.3, 0.5]
        }
    }
}
```

**Points d'√©valuation couverts :** 5 points (Testing different optimizer) + 5 points (Optimizing learning rate)

---

### 1.2 Syst√®me d'export des m√©triques ‚úÖ

**Fichier cr√©√© : `metrics_exporter.py`**

Fonctionnalit√©s :
- [x] Export en CSV des m√©triques par √©poque (train loss, train acc, val loss, val acc)
- [x] Export en JSON des r√©sultats finaux de chaque exp√©rience
- [x] Sauvegarde automatique des hyperparam√®tres utilis√©s
- [x] Calcul du nombre de param√®tres entra√Ænables

Structure de sortie :
```
results/
‚îú‚îÄ‚îÄ experiments.csv          # R√©sum√© de toutes les exp√©riences
‚îú‚îÄ‚îÄ learning_curves/         # Courbes d'apprentissage par exp√©rience
‚îÇ   ‚îú‚îÄ‚îÄ MLP_exp001.csv
‚îÇ   ‚îú‚îÄ‚îÄ LSTM_exp002.csv
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ best_models/             # Meilleurs mod√®les sauvegard√©s
    ‚îú‚îÄ‚îÄ best_MLP.pth
    ‚îî‚îÄ‚îÄ best_LSTM.pth
```

**Points d'√©valuation couverts :** 5 points (Calculating learning curve) + 5 points (Analysing learning curves)

---

## Phase 2 : Optimisation des Architectures (Priorit√© Haute)

### 2.1 Optimisation MLP

**Fichier √† modifier : `networks_2100078.py`**

Exp√©riences √† mener :
- [ ] Tester diff√©rentes profondeurs (1, 2, 3, 4 couches cach√©es)
- [ ] Tester diff√©rentes largeurs (64, 128, 256, 512 neurones)
- [ ] Tester diff√©rents taux de dropout (0, 0.2, 0.3, 0.5)
- [ ] Documenter le nombre de poids entra√Ænables pour chaque configuration

**Points d'√©valuation couverts :** 5 points (Optimizing MLP architecture)

---

### 2.2 Optimisation LSTM

**Fichier √† modifier : `networks_2100078.py`**

Exp√©riences √† mener :
- [ ] Tester diff√©rents `hidden_size` (64, 128, 256)
- [ ] Tester diff√©rents `num_layers` (1, 2, 3)
- [ ] Tester bidirectionnel vs unidirectionnel
- [ ] Tester diff√©rents taux de dropout (0, 0.2, 0.3, 0.5)
- [ ] Documenter le nombre de poids entra√Ænables pour chaque configuration

**Points d'√©valuation couverts :** 5 points (Optimizing LSTM architecture)

---

### 2.3 Impl√©mentation CNN (Bonus)

**Fichier √† cr√©er/modifier : `networks_2100078.py`**

Architecture propos√©e :
```python
class CNN(nn.Module):
    def __init__(self, input_size, output_size, filters, kernel_size, dropout):
        # Conv1D layers
        # BatchNorm layers
        # MaxPooling layers
        # Fully connected layers
```

Exp√©riences :
- [ ] Tester diff√©rentes tailles de filtres
- [ ] Tester diff√©rentes tailles de kernel
- [ ] Optimiser l'architecture

**Points d'√©valuation couverts :** 10 points (Implementation of CNN)

---

### 2.4 Impl√©mentation CNN-LSTM ou Transformer (Bonus)

**Options :**

**Option A - CNN-LSTM :**
```python
class CNN_LSTM(nn.Module):
    # CNN pour extraction de features locales
    # LSTM pour s√©quences temporelles
```

**Option B - Transformer :**
```python
class TransformerModel(nn.Module):
    # Positional Encoding
    # Multi-Head Attention
    # Feed Forward layers
```

**Points d'√©valuation couverts :** 10 points (Implementation of new architecture)

---

## Phase 3 : Entra√Ænement et √âvaluation ‚úÖ TERMIN√âE

### 3.1 Script d'entra√Ænement automatis√© ‚úÖ

**Fichier cr√©√© : `run_experiments.py`**

Fonctionnalit√©s :
- [x] Boucle sur toutes les combinaisons d'hyperparam√®tres
- [x] Sauvegarde automatique des r√©sultats
- [x] Early stopping pour √©viter l'overfitting
- [x] Logging d√©taill√©

```python
def run_experiment(model_type, config):
    # 1. Cr√©er le mod√®le
    # 2. Configurer l'optimizer
    # 3. Entra√Æner
    # 4. √âvaluer sur dev/test
    # 5. Sauvegarder les m√©triques
    # 6. Sauvegarder le mod√®le si meilleur
```

**Points d'√©valuation couverts :** 5 points (Checking impact of epochs and batch size)

---

### 3.2 Utilisation de toutes les donn√©es ‚úÖ

**Fichier cr√©√© : `data_extended.py`**

Actions :
- [x] Modifier le chargement pour inclure toutes les parties (pas seulement les gagnants)
- [x] Adapter les labels en cons√©quence
- [x] V√©rifier l'√©quilibrage des classes
- [x] Mode configurable (use_all_samples=True/False)

**Points d'√©valuation couverts :** 5 points (Using all data)

---

### 3.3 G√©n√©ration de courbes d'apprentissage ‚úÖ

**Fichier cr√©√© : `plot_learning_curves.py`**

Fonctionnalit√©s :
- [x] Graphique Train Loss vs Val Loss par √©poque
- [x] Graphique Train Accuracy vs Val Accuracy par √©poque
- [x] D√©tection de l'overfitting/underfitting
- [x] Export en PNG/PDF
- [x] Heatmaps d'hyperparam√®tres
- [x] Comparaisons entre mod√®les
- [x] Rapport d'overfitting automatique

**Points d'√©valuation couverts :** 5 points (Calculating learning curve) + 10 points (Analysing learning curves)

---

## Phase 4 : M√©triques Avanc√©es (Priorit√© Moyenne)

### 4.1 M√©triques de jeu

**Fichier √† cr√©er : `game_metrics.py`**

M√©triques √† impl√©menter :
- [ ] **Game Win Ratio** : Ratio de parties gagn√©es par le mod√®le
- [ ] **Legal Move Ratio** : Ratio de coups l√©gaux pr√©dits par le mod√®le
- [ ] Matrice de confusion des coups

**Points d'√©valuation couverts :** 5 points (Analysing different evaluation metrics)

---

## Phase 5 : G√©n√©ration de Donn√©es (Bonus - Priorit√© Basse)

### 5.1 Syst√®me de g√©n√©ration de nouvelles parties

**Fichier √† cr√©er : `generate_data.py`**

Fonctionnalit√©s :
- [ ] Faire jouer deux IA l'une contre l'autre
- [ ] Logger les coups et √©tats du jeu
- [ ] Convertir les logs au format H5
- [ ] Ajouter au dataset d'entra√Ænement

```python
def generate_games(model1, model2, num_games=1000):
    for i in range(num_games):
        game = Game()
        while not game.is_finished():
            if game.current_player == 1:
                move = model1.predict(game.state)
            else:
                move = model2.predict(game.state)
            game.play(move)
        save_game_to_h5(game)
```

**Points d'√©valuation couverts :** 20 points (Generate new data)

---

## Phase 6 : Finalisation (Priorit√© Haute)

### 6.1 Entra√Ænement final avec toutes les donn√©es

Actions :
- [ ] Identifier le meilleur mod√®le et ses hyperparam√®tres
- [ ] R√©entra√Æner sur train + dev (ou train + test)
- [ ] √âvaluer les performances finales

**Points d'√©valuation couverts :** 5 points (Using more data in final training)

---

### 6.2 Documentation et Pr√©sentation

Actions :
- [ ] Compl√©ter le rapport avec tous les r√©sultats
- [ ] Cr√©er des tableaux comparatifs
- [ ] Pr√©parer la pr√©sentation de 5 minutes

**Points d'√©valuation couverts :** 10 points (Presentation) + 5 points (Experiment design)

---

## Ordre de Priorit√© Recommand√©

| Priorit√© | T√¢che | Points | Temps estim√© |
|----------|-------|--------|--------------|
| 1 | Baseline MLP + LSTM | 5 | 1h |
| 2 | Infrastructure m√©triques | 10 | 2h |
| 3 | Optimisation MLP | 5 | 2h |
| 4 | Optimisation LSTM | 5 | 2h |
| 5 | Test optimizers + learning rates | 10 | 2h |
| 6 | Test batch size + epochs | 5 | 1h |
| 7 | Courbes d'apprentissage | 15 | 2h |
| 8 | Utiliser toutes les donn√©es | 5 | 1h |
| 9 | M√©triques de jeu | 5 | 2h |
| 10 | Impl√©mentation CNN | 10 | 3h |
| 11 | CNN-LSTM ou Transformer | 10 | 4h |
| 12 | G√©n√©ration de donn√©es | 20 | 5h |
| 13 | Entra√Ænement final | 5 | 1h |
| 14 | Rapport et pr√©sentation | 15 | 3h |

**Total potentiel : 127 points** (certains bonus)

---

## Fichiers √† Cr√©er

1. ‚úÖ `config_experiments.py` - Configuration centralis√©e
2. ‚úÖ `metrics_exporter.py` - Export des m√©triques
3. ‚úÖ `run_experiments.py` - Script d'entra√Ænement automatis√©
4. ‚úÖ `plot_learning_curves.py` - Visualisation des courbes
5. ‚úÖ `data_extended.py` - Chargement de toutes les donn√©es
6. ‚è≥ `game_metrics.py` - M√©triques sp√©cifiques au jeu
7. ‚è≥ `generate_data.py` - G√©n√©ration de nouvelles donn√©es

---

## Fichiers √† Modifier

1. ‚è≥ `networks_2100078.py` - Ajout CNN, CNN-LSTM, Transformer
2. ‚è≥ `training_Many2One.py` / `training_One2One.py` - Int√©gration du syst√®me de m√©triques (optionnel)

---

## Checklist de Validation

- [x] Les r√©sultats sont √©valu√©s sur dev/test (pas train) ‚Üí **√âviter -10 points**
- [x] Le nombre de param√®tres est report√© pour chaque architecture
- [ ] Tous les tableaux/figures ont des nombres (en cours avec les exp√©riences)
- [ ] Les conclusions sont logiques et justifi√©es (apr√®s analyse des r√©sultats)
- [ ] La pr√©sentation respecte les 5 minutes

---

## √âtat d'Avancement

### ‚úÖ Phases Compl√©t√©es

- **Phase 1** : Infrastructure et Configuration (10 points)
  - config_experiments.py
  - metrics_exporter.py
  
- **Phase 3** : Entra√Ænement et √âvaluation (35 points)
  - run_experiments.py
  - plot_learning_curves.py
  - data_extended.py

**Points acquis : ~45 points**

### ‚è≥ Phases En Cours

- **Phase 2** : Optimisation des Architectures (20-30 points)
  - N√©cessite de lancer les exp√©riences avec run_experiments.py
  - Analyse des r√©sultats pour identifier les meilleures architectures

### üìã Phases Restantes

- **Phase 4** : M√©triques Avanc√©es (5 points)
- **Phase 5** : G√©n√©ration de Donn√©es (20 points - bonus)
- **Phase 6** : Finalisation et Pr√©sentation (20 points)

### üöÄ Prochaines Actions Recommand√©es

1. **Lancer les exp√©riences baseline** :
   ```bash
   python run_experiments.py --models MLP LSTM --max-exp 10
   ```

2. **G√©n√©rer les visualisations** :
   ```bash
   python plot_learning_curves.py
   ```

3. **Analyser les r√©sultats** pour identifier :
   - Meilleurs optimizers
   - Meilleurs learning rates
   - Meilleures architectures MLP/LSTM

4. **Impl√©menter CNN** (Phase 2.3) si le temps le permet

5. **Impl√©menter game_metrics.py** (Phase 4.1)

6. **R√©diger le rapport** avec les r√©sultats obtenus
