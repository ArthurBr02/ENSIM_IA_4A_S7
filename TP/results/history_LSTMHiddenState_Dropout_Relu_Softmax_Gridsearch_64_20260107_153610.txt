Historique d'entraînement - LSTMHiddenState_Dropout_Relu_Softmax_Gridsearch_64
============================================================
Date: 2026-01-07 15:36:10
Optimizer: Adam
Learning Rate: 0.005
Meilleure époque: 47
Époques complétées: 50
Meilleure accuracy dev: 0.2149 (21.49%)
Meilleure loss dev: 3.9706
Temps total d'entraînement: 539.03 sec

============================================================
Historique par époque:
Epoch    Train Acc    Dev Acc      Train Loss   Dev Loss    
------------------------------------------------------------
1        0.1284       0.1182       4.0884       4.0681      
2        0.1504       0.1364       4.0524       4.0504      
3        0.1707       0.1487       4.0329       4.0376      
4        0.1847       0.1581       4.0169       4.0281      
5        0.1993       0.1682       4.0043       4.0177      
6        0.2090       0.1756       3.9939       4.0109      
7        0.2173       0.1820       3.9850       4.0046      
8        0.2243       0.1851       3.9780       4.0018      
9        0.2309       0.1870       3.9717       3.9992      
10       0.2338       0.1879       3.9671       3.9983      
11       0.2390       0.1902       3.9625       3.9950      
12       0.2438       0.1927       3.9592       3.9932      
13       0.2471       0.1957       3.9549       3.9907      
14       0.2506       0.1960       3.9523       3.9899      
15       0.2534       0.1977       3.9501       3.9894      
16       0.2553       0.1974       3.9463       3.9880      
17       0.2585       0.1998       3.9442       3.9863      
18       0.2610       0.2008       3.9416       3.9856      
19       0.2609       0.1975       3.9397       3.9880      
20       0.2660       0.2003       3.9377       3.9857      
21       0.2677       0.1996       3.9359       3.9853      
22       0.2693       0.2009       3.9339       3.9844      
23       0.2704       0.2011       3.9322       3.9840      
24       0.2716       0.2012       3.9313       3.9847      
25       0.2724       0.2022       3.9286       3.9834      
26       0.2760       0.2032       3.9280       3.9824      
27       0.2778       0.2048       3.9259       3.9811      
28       0.2793       0.2041       3.9245       3.9813      
29       0.2813       0.2067       3.9229       3.9787      
30       0.2810       0.2064       3.9209       3.9789      
31       0.2831       0.2064       3.9208       3.9787      
32       0.2858       0.2062       3.9202       3.9792      
33       0.2849       0.2068       3.9190       3.9790      
34       0.2864       0.2104       3.9169       3.9761      
35       0.2868       0.2077       3.9165       3.9779      
36       0.2891       0.2095       3.9164       3.9765      
37       0.2892       0.2092       3.9155       3.9769      
38       0.2897       0.2061       3.9144       3.9785      
39       0.2909       0.2102       3.9140       3.9753      
40       0.2930       0.2105       3.9127       3.9747      
41       0.2920       0.2100       3.9127       3.9756      
42       0.2939       0.2081       3.9106       3.9767      
43       0.2948       0.2107       3.9099       3.9752      
44       0.2963       0.2118       3.9088       3.9742      
45       0.2973       0.2125       3.9073       3.9728      
46       0.3004       0.2143       3.9061       3.9709      
47       0.3008       0.2149       3.9054       3.9706      
48       0.2999       0.2144       3.9050       3.9706      
49       0.3007       0.2143       3.9044       3.9710      
50       0.3013       0.2144       3.9040       3.9708      
